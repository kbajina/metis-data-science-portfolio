{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL TABLES SETUP\n",
    "This project utilizes a series of tables from a Kaggle data set meant to examine default risk status of mortgage applicants.\n",
    "\n",
    "This notebook will be used to set up the SQL Statements for creating new database tables based on these existing .csv files. Some of these files contain 100+ fields. To avoid manually typing out the table schemas, this notebook imports small segments of each .csv file and helps compose the CREATE TABLE statements. This is done to work with PostgreSQL via command line and not via a GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Common Python Modules:\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) APPLICATION TABLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data into Pandas:\n",
    "Errors occured with trying to import .csv file directly to PostgreSQL. For this reason, Pandas is useful for preprocessing data and casting values correctly before loading into SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data_files/home-credit-default-risk/application_train.csv' does not exist: b'data_files/home-credit-default-risk/application_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d5cd945095c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Read application_train .csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mapplication_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data_files/home-credit-default-risk/application_train.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mapplication_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplication_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data_files/home-credit-default-risk/application_train.csv' does not exist: b'data_files/home-credit-default-risk/application_train.csv'"
     ]
    }
   ],
   "source": [
    "## Read application_train .csv file\n",
    "application_path = 'data_files/home-credit-default-risk/application_train.csv'\n",
    "application_df = pd.read_csv(application_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create Pandas Series of all field data types\n",
    "application_dtypes = pd.Series(application_df.dtypes)\n",
    "\n",
    "## Create a list of tuples with every field in `application_df` and it's corresponding data type\n",
    "application_schema = list(zip(application_dtypes.index.values, application_dtypes.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL code for dataframe fields:\n",
    "Print list of fields in `application_df` with their respective data types. This output will be used in for creating a new table in PostgreSQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK_ID_CURR INT, \n",
      "TARGET INT, \n",
      "NAME_CONTRACT_TYPE VARCHAR, \n",
      "CODE_GENDER VARCHAR, \n",
      "FLAG_OWN_CAR VARCHAR, \n",
      "FLAG_OWN_REALTY VARCHAR, \n",
      "CNT_CHILDREN INT, \n",
      "AMT_INCOME_TOTAL DECIMAL, \n",
      "AMT_CREDIT DECIMAL, \n",
      "AMT_ANNUITY DECIMAL, \n",
      "AMT_GOODS_PRICE DECIMAL, \n",
      "NAME_TYPE_SUITE VARCHAR, \n",
      "NAME_INCOME_TYPE VARCHAR, \n",
      "NAME_EDUCATION_TYPE VARCHAR, \n",
      "NAME_FAMILY_STATUS VARCHAR, \n",
      "NAME_HOUSING_TYPE VARCHAR, \n",
      "REGION_POPULATION_RELATIVE DECIMAL, \n",
      "DAYS_BIRTH INT, \n",
      "DAYS_EMPLOYED INT, \n",
      "DAYS_REGISTRATION DECIMAL, \n",
      "DAYS_ID_PUBLISH INT, \n",
      "OWN_CAR_AGE DECIMAL, \n",
      "FLAG_MOBIL INT, \n",
      "FLAG_EMP_PHONE INT, \n",
      "FLAG_WORK_PHONE INT, \n",
      "FLAG_CONT_MOBILE INT, \n",
      "FLAG_PHONE INT, \n",
      "FLAG_EMAIL INT, \n",
      "OCCUPATION_TYPE VARCHAR, \n",
      "CNT_FAM_MEMBERS DECIMAL, \n",
      "REGION_RATING_CLIENT INT, \n",
      "REGION_RATING_CLIENT_W_CITY INT, \n",
      "WEEKDAY_APPR_PROCESS_START VARCHAR, \n",
      "HOUR_APPR_PROCESS_START INT, \n",
      "REG_REGION_NOT_LIVE_REGION INT, \n",
      "REG_REGION_NOT_WORK_REGION INT, \n",
      "LIVE_REGION_NOT_WORK_REGION INT, \n",
      "REG_CITY_NOT_LIVE_CITY INT, \n",
      "REG_CITY_NOT_WORK_CITY INT, \n",
      "LIVE_CITY_NOT_WORK_CITY INT, \n",
      "ORGANIZATION_TYPE VARCHAR, \n",
      "EXT_SOURCE_1 DECIMAL, \n",
      "EXT_SOURCE_2 DECIMAL, \n",
      "EXT_SOURCE_3 DECIMAL, \n",
      "APARTMENTS_AVG DECIMAL, \n",
      "BASEMENTAREA_AVG DECIMAL, \n",
      "YEARS_BEGINEXPLUATATION_AVG DECIMAL, \n",
      "YEARS_BUILD_AVG DECIMAL, \n",
      "COMMONAREA_AVG DECIMAL, \n",
      "ELEVATORS_AVG DECIMAL, \n",
      "ENTRANCES_AVG DECIMAL, \n",
      "FLOORSMAX_AVG DECIMAL, \n",
      "FLOORSMIN_AVG DECIMAL, \n",
      "LANDAREA_AVG DECIMAL, \n",
      "LIVINGAPARTMENTS_AVG DECIMAL, \n",
      "LIVINGAREA_AVG DECIMAL, \n",
      "NONLIVINGAPARTMENTS_AVG DECIMAL, \n",
      "NONLIVINGAREA_AVG DECIMAL, \n",
      "APARTMENTS_MODE DECIMAL, \n",
      "BASEMENTAREA_MODE DECIMAL, \n",
      "YEARS_BEGINEXPLUATATION_MODE DECIMAL, \n",
      "YEARS_BUILD_MODE DECIMAL, \n",
      "COMMONAREA_MODE DECIMAL, \n",
      "ELEVATORS_MODE DECIMAL, \n",
      "ENTRANCES_MODE DECIMAL, \n",
      "FLOORSMAX_MODE DECIMAL, \n",
      "FLOORSMIN_MODE DECIMAL, \n",
      "LANDAREA_MODE DECIMAL, \n",
      "LIVINGAPARTMENTS_MODE DECIMAL, \n",
      "LIVINGAREA_MODE DECIMAL, \n",
      "NONLIVINGAPARTMENTS_MODE DECIMAL, \n",
      "NONLIVINGAREA_MODE DECIMAL, \n",
      "APARTMENTS_MEDI DECIMAL, \n",
      "BASEMENTAREA_MEDI DECIMAL, \n",
      "YEARS_BEGINEXPLUATATION_MEDI DECIMAL, \n",
      "YEARS_BUILD_MEDI DECIMAL, \n",
      "COMMONAREA_MEDI DECIMAL, \n",
      "ELEVATORS_MEDI DECIMAL, \n",
      "ENTRANCES_MEDI DECIMAL, \n",
      "FLOORSMAX_MEDI DECIMAL, \n",
      "FLOORSMIN_MEDI DECIMAL, \n",
      "LANDAREA_MEDI DECIMAL, \n",
      "LIVINGAPARTMENTS_MEDI DECIMAL, \n",
      "LIVINGAREA_MEDI DECIMAL, \n",
      "NONLIVINGAPARTMENTS_MEDI DECIMAL, \n",
      "NONLIVINGAREA_MEDI DECIMAL, \n",
      "FONDKAPREMONT_MODE VARCHAR, \n",
      "HOUSETYPE_MODE VARCHAR, \n",
      "TOTALAREA_MODE DECIMAL, \n",
      "WALLSMATERIAL_MODE VARCHAR, \n",
      "EMERGENCYSTATE_MODE VARCHAR, \n",
      "OBS_30_CNT_SOCIAL_CIRCLE DECIMAL, \n",
      "DEF_30_CNT_SOCIAL_CIRCLE DECIMAL, \n",
      "OBS_60_CNT_SOCIAL_CIRCLE DECIMAL, \n",
      "DEF_60_CNT_SOCIAL_CIRCLE DECIMAL, \n",
      "DAYS_LAST_PHONE_CHANGE DECIMAL, \n",
      "FLAG_DOCUMENT_2 INT, \n",
      "FLAG_DOCUMENT_3 INT, \n",
      "FLAG_DOCUMENT_4 INT, \n",
      "FLAG_DOCUMENT_5 INT, \n",
      "FLAG_DOCUMENT_6 INT, \n",
      "FLAG_DOCUMENT_7 INT, \n",
      "FLAG_DOCUMENT_8 INT, \n",
      "FLAG_DOCUMENT_9 INT, \n",
      "FLAG_DOCUMENT_10 INT, \n",
      "FLAG_DOCUMENT_11 INT, \n",
      "FLAG_DOCUMENT_12 INT, \n",
      "FLAG_DOCUMENT_13 INT, \n",
      "FLAG_DOCUMENT_14 INT, \n",
      "FLAG_DOCUMENT_15 INT, \n",
      "FLAG_DOCUMENT_16 INT, \n",
      "FLAG_DOCUMENT_17 INT, \n",
      "FLAG_DOCUMENT_18 INT, \n",
      "FLAG_DOCUMENT_19 INT, \n",
      "FLAG_DOCUMENT_20 INT, \n",
      "FLAG_DOCUMENT_21 INT, \n",
      "AMT_REQ_CREDIT_BUREAU_HOUR DECIMAL, \n",
      "AMT_REQ_CREDIT_BUREAU_DAY DECIMAL, \n",
      "AMT_REQ_CREDIT_BUREAU_WEEK DECIMAL, \n",
      "AMT_REQ_CREDIT_BUREAU_MON DECIMAL, \n",
      "AMT_REQ_CREDIT_BUREAU_QRT DECIMAL, \n",
      "AMT_REQ_CREDIT_BUREAU_YEAR DECIMAL, \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(application_schema)):\n",
    "    \n",
    "    if application_schema[i][1] == 'int64':\n",
    "        print(application_schema[i][0], \"INT, \")\n",
    "        \n",
    "    elif application_schema[i][1] == 'O':\n",
    "        print(application_schema[i][0], \"VARCHAR, \")\n",
    "        \n",
    "    elif application_schema[i][1] == 'float64':\n",
    "        print(application_schema[i][0], \"DECIMAL, \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) BUREAU DATA TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read bureau.csv file\n",
    "## Limit load to first 10 rows\n",
    "## Only need this data for creating SQL schema\n",
    "\n",
    "bureau_path = 'data_files/home-credit-default-risk/bureau.csv'\n",
    "bureau_df = pd.read_csv(bureau_path, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create Pandas Series of all field data types\n",
    "bureau_dtypes = pd.Series(bureau_df.dtypes)\n",
    "\n",
    "## Create a list of tuples with every field in `application_df` and it's corresponding data type\n",
    "bureau_schema = list(zip(bureau_dtypes.index.values, bureau_dtypes.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK_ID_CURR INT, \n",
      "SK_ID_BUREAU INT, \n",
      "CREDIT_ACTIVE VARCHAR, \n",
      "CREDIT_CURRENCY VARCHAR, \n",
      "DAYS_CREDIT INT, \n",
      "CREDIT_DAY_OVERDUE INT, \n",
      "DAYS_CREDIT_ENDDATE DECIMAL, \n",
      "DAYS_ENDDATE_FACT DECIMAL, \n",
      "AMT_CREDIT_MAX_OVERDUE DECIMAL, \n",
      "CNT_CREDIT_PROLONG INT, \n",
      "AMT_CREDIT_SUM DECIMAL, \n",
      "AMT_CREDIT_SUM_DEBT DECIMAL, \n",
      "AMT_CREDIT_SUM_LIMIT DECIMAL, \n",
      "AMT_CREDIT_SUM_OVERDUE DECIMAL, \n",
      "CREDIT_TYPE VARCHAR, \n",
      "DAYS_CREDIT_UPDATE INT, \n",
      "AMT_ANNUITY DECIMAL, \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(bureau_schema)):\n",
    "    \n",
    "    if bureau_schema[i][1] == 'int64':\n",
    "        print(bureau_schema[i][0], \"INT, \")\n",
    "        \n",
    "    elif bureau_schema[i][1] == 'O':\n",
    "        print(bureau_schema[i][0], \"VARCHAR, \")\n",
    "        \n",
    "    elif bureau_schema[i][1] == 'float64':\n",
    "        print(bureau_schema[i][0], \"DECIMAL, \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Additional Tables\n",
    "Use the above code for import process of the following additional tables:\n",
    "- bureau_balance.csv\n",
    "- credit_card_balance.csv\n",
    "- installments_payments.csv\n",
    "- POS_CASH_balance.csv\n",
    "- previous_application.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
